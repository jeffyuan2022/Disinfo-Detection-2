---
layout: default
title: AI-Powered Misinformation Detection
---

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{{ page.title }}</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 40px;
            padding: 0;
            background-color: #f4f4f4;
        }
        .container {
            max-width: 900px;
            margin: auto;
            background: white;
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
        }
        h1, h2, h3 {
            color: #333;
        }
        a {
            color: #007bff;
            text-decoration: none;
        }
        .footer {
            margin-top: 20px;
            text-align: center;
            font-size: 0.9em;
            color: gray;
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>Hybrid AI for Disinformation Detection</h1>
            <p><strong>Authors:</strong> Yiheng Yuan, Luran Zhang, Jade Zhou, Dr. Ali Arsanjani</p>
            <p><strong>Affiliation:</strong> Halıcıoğlu Data Science Institute, University of California, San Diego</p>
        </header>

        <section>
            <h2>Abstract</h2>
            <p>
                The spread of misinformation threatens public trust and informed decision-making. Our project aims to 
                combat this issue using a hybrid AI system that combines predictive and generative models to detect, 
                rank, and mitigate false content in news articles. 
            </p>
            <p>
                Using the <strong>LIAR-PLUS dataset</strong> and an evolving set of <strong>Factuality Factors</strong>, 
                we develop an AI pipeline that assigns veracity scores through machine learning and refines assessments using 
                <strong>Fractal Chain of Thought (FCoT)</strong> prompting. Key innovations include:
            </p>
            <ul>
                <li>Advanced web scraping with real-time search validation</li>
                <li>Vector database storage for efficient retrieval</li>
                <li>Hybrid AI combining structured analysis with generative reasoning</li>
            </ul>
        </section>

        <section>
            <h2>Introduction</h2>
            <p>
                The internet has made information more accessible than ever, but it has also amplified misinformation and 
                disinformation. While misinformation is the unintentional spread of false information, disinformation is 
                deliberately misleading content. Both erode public trust and distort understanding of critical issues.
            </p>
            <p>
                To address this, we developed an AI-powered misinformation detection system. Our approach integrates a 
                predictive machine learning model with a generative AI model to evaluate online content with greater 
                accuracy and contextual understanding.
            </p>
        </section>

        <section>
            <h2>How It Works</h2>

            <h3>Step 1: Scraping and Structuring Data</h3>
            <p>
                We scrape articles from fact-checking sites like Politifact and supplement them with search engine queries 
                using SerpAPI. The collected text is stored in <strong>Weaviate</strong>, a vector database optimized for 
                fast retrieval and similarity searches.
            </p>

            <h3>Step 2: Predictive Model – Feature Extraction and Classification</h3>
            <p>
                The predictive model assesses factuality based on structured linguistic and content-based features. 
                We use techniques like:
            </p>
            <ul>
                <li><strong>TF-IDF and CountVectorizer:</strong> Extracts key textual patterns</li>
                <li><strong>Sentiment Analysis:</strong> Detects subjective vs. objective language</li>
                <li><strong>Random Forest Classification:</strong> Predicts statement credibility</li>
            </ul>
            <p>
                The model outputs a <strong>veracity score</strong> ranging from 0 to 1, where 1 represents the highest 
                factual accuracy.
            </p>

            <h3>Step 3: Generative AI – Refining Truthfulness with Context</h3>
            <p>
                The generative AI model (Google Gemini) evaluates statements beyond numerical patterns. It examines biases, 
                consistency, and relevance using structured <strong>Fractal Chain of Thought (FCoT)</strong> prompting.
            </p>
            <p>
                <strong>Why FCoT?</strong> Traditional AI models often generate inconsistent results across different text chunks. 
                FCoT mitigates this by guiding the AI through iterative reasoning steps, improving response stability.
            </p>

            <h3>Step 4: Hybrid Approach – Combining Both Models</h3>
            <p>
                By integrating structured predictive features with generative AI reasoning, our model achieves:
            </p>
            <ul>
                <li>Higher accuracy in factuality assessments</li>
                <li>Greater consistency across different sources</li>
                <li>Transparency in how misinformation is detected</li>
            </ul>
        </section>

        <section>
            <h2>Evaluation and Results</h2>
            <p>
                Our model performs well in distinguishing factual vs. misleading content. Notably, 
                <strong>FCoT-based generative evaluations</strong> provide more stable truthfulness scores compared to standard 
                AI prompting. Figures below illustrate how FCoT reduces fluctuations and aligns results with human fact-checking 
                patterns.
            </p>

            <figure>
                <img src="Screenshot_2024-12-04_14-17-06.png" width="100%" alt="Comparison of Truthfulness Scores">
                <figcaption>Truthfulness score consistency between FCoT and traditional prompting.</figcaption>
            </figure>
        </section>

        <section>
            <h2>Challenges and Future Work</h2>
            <p>
                While our model demonstrates strong performance, we recognize key areas for improvement:
            </p>
            <ul>
                <li>Expanding to <strong>12 Factuality Factors</strong> for deeper analysis</li>
                <li>Refining neural networks for predictive scoring</li>
                <li>Optimizing data retrieval through improved ranking mechanisms</li>
                <li>Enhancing the <strong>Mesop UI</strong> for an intuitive user experience</li>
            </ul>
            <p>
                We are also exploring alternatives to SerpAPI for better real-time search performance.
            </p>
        </section>

        <section>
            <h2>Acknowledgments</h2>
            <p>
                We extend our gratitude to <strong>Dr. Ali Arsanjani</strong> (Google Cloud, Applied AI Engineering) for his 
                mentorship and guidance throughout this project.
            </p>
        </section>

        <footer class="footer">
            <p>&copy; 2024 Yiheng Yuan, Luran Zhang, Jade Zhou, Dr. Ali Arsanjani</p>
            <p><a href="https://github.com/jeffyuan2022/Disinfo-Detection-2/tree/main">Explore our GitHub repository</a></p>
        </footer>
    </div>
</body>
</html>

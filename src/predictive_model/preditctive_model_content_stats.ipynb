{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e2c1f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laurenzhang/Desktop/UCSD/DSC capstone/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "from textblob import TextBlob\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21dc73c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data\n",
    "train = pd.read_csv('../data/train2.tsv', sep='\\t', header=None)\n",
    "test = pd.read_csv('../data/test2.tsv', sep='\\t', header=None)\n",
    "column_names = [\n",
    "    \"Index\",\n",
    "    \"ID\",\n",
    "    \"Label\",\n",
    "    \"Statement\",\n",
    "    \"Subject\",\n",
    "    \"Speaker\",\n",
    "    \"Speaker_Job_Title\",\n",
    "    \"State_Info\",\n",
    "    \"Party_Affiliation\",\n",
    "    \"Barely_True_Counts\",\n",
    "    \"False_Counts\",\n",
    "    \"Half_True_Counts\",\n",
    "    \"Mostly_True_Counts\",\n",
    "    \"Pants_On_Fire_Counts\",\n",
    "    \"Context\",\n",
    "    \"Extracted_Justification\"\n",
    "]\n",
    "\n",
    "train.columns = column_names\n",
    "test.columns = column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e1a476ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 31\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Check for missing values\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# print(train.isnull().sum())\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m \n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# print(train.isnull().sum())\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum())\n\u001b[1;32m     33\u001b[0m data \u001b[38;5;241m=\u001b[39m data_clean(data)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(data\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "def data_clean(df):\n",
    "\n",
    "    # Fill missing values in text-based columns\n",
    "    df.replace({'Statement':''}, np.nan, inplace=True)\n",
    "    df.replace({'Extracted_Justification':''}, np.nan, inplace=True)\n",
    "\n",
    "    # Drop rows with missing 'Statement' or 'Extracted_Justification' (since these are critical)\n",
    "    df.dropna(subset=['Statement', 'Extracted_Justification'], inplace=True)\n",
    "\n",
    "    # Drop rows with missing labels\n",
    "    df = df.dropna(subset=['Label'])\n",
    "\n",
    "    # Impute missing values in categorical columns with 'Unknown'\n",
    "    categorical_columns = ['Speaker', 'Speaker_Job_Title', 'State_Info', 'Party_Affiliation', 'Context']\n",
    "    df[categorical_columns] = df[categorical_columns].fillna('Unknown')\n",
    "\n",
    "    # Impute numerical columns (truth counts) with median values\n",
    "    numeric_columns = [\"Barely_True_Counts\", \"False_Counts\", \"Half_True_Counts\", \"Mostly_True_Counts\", \"Pants_On_Fire_Counts\"]\n",
    "    df[numeric_columns] = df[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "    df[numeric_columns] = df[numeric_columns].fillna(df[numeric_columns].median())\n",
    "    return df\n",
    "\n",
    "# Check for missing values\n",
    "print(train.isnull().sum())\n",
    "\n",
    "train = data_clean(train)\n",
    "test = data_clean(test)\n",
    "\n",
    "print(train.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f72626eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding for categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "train['Label'] = label_encoder.fit_transform(train['Label'])  # Encoding labels like \"false\", \"half-true\", etc. to 0, 1...\n",
    "test['Label'] = label_encoder.fit_transform(test['Label'])  # Encoding labels like \"false\", \"half-true\", etc. to 0, 1...\n",
    "\n",
    "train['Text'] = train['Statement'] + ' ' + train['Extracted_Justification']\n",
    "test['Text'] = test['Statement'] + ' ' + test['Extracted_Justification']\n",
    "\n",
    "X_train = train[['Text']]\n",
    "y_train = train['Label']\n",
    "X_test = test[['Text']]\n",
    "y_test = test['Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ff8211",
   "metadata": {},
   "source": [
    "## Content Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a165690e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4f28442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained NLP model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bff9fdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def structural_analysis(statement):\n",
    "    doc = nlp(statement)\n",
    "    num_sentences = len(list(doc.sents))\n",
    "    total_tokens = len([token.text for token in doc])\n",
    "    \n",
    "    # Syntactic complexity\n",
    "    avg_sentence_length = total_tokens / num_sentences if num_sentences > 0 else 0\n",
    "    tree_depth = max([token.head.i - token.i for token in doc]) if len(doc) > 0 else 0\n",
    "    \n",
    "    # Sentiment Analysis\n",
    "    sentiment = TextBlob(statement).sentiment\n",
    "    polarity = sentiment.polarity\n",
    "    subjectivity = sentiment.subjectivity\n",
    "\n",
    "    return [avg_sentence_length, tree_depth, polarity, subjectivity]\n",
    "\n",
    "def extract_graph_features(statement):\n",
    "    doc = nlp(statement)\n",
    "    pos_counts = Counter([token.pos_ for token in doc])\n",
    "    entities = Counter([ent.label_ for ent in doc.ents])\n",
    "    \n",
    "    # part of speech tagging\n",
    "    pos_noun = pos_counts.get(\"NOUN\", 0)\n",
    "    pos_verb = pos_counts.get(\"VERB\", 0)\n",
    "    pos_adjective = pos_counts.get(\"ADJ\", 0)\n",
    "    \n",
    "    # named entity recognition\n",
    "    num_persons = entities.get(\"PERSON\", 0)\n",
    "    num_orgs = entities.get(\"ORG\", 0)\n",
    "    num_gpes = entities.get(\"GPE\", 0)\n",
    "    \n",
    "    return [pos_noun, pos_verb, pos_adjective, num_persons, num_orgs, num_gpes]\n",
    "\n",
    "def extract_comparison_features(statement):\n",
    "    # Keywords for different LIWC-like categories (simplified)\n",
    "    cognitive_words = [\"think\", \"know\", \"understand\", \"believe\"]\n",
    "    emotional_words = [\"happy\", \"sad\", \"angry\", \"fear\"]\n",
    "    social_words = [\"friend\", \"family\", \"society\"]\n",
    "\n",
    "    # Tokenize statement and count keywords\n",
    "    vectorizer = CountVectorizer(vocabulary=cognitive_words + emotional_words + social_words)\n",
    "    word_counts = vectorizer.fit_transform([statement]).toarray().flatten()\n",
    "\n",
    "    # Divide word counts into different categories\n",
    "    num_cognitive = sum(word_counts[:len(cognitive_words)])\n",
    "    num_emotional = sum(word_counts[len(cognitive_words):len(cognitive_words) + len(emotional_words)])\n",
    "    num_social = sum(word_counts[-len(social_words):])\n",
    "\n",
    "    return [num_cognitive, num_emotional, num_social]\n",
    "    \n",
    "def extract_feature(statement):\n",
    "    return structural_analysis(statement) + extract_graph_features(statement) + extract_comparison_features(statement)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbca1141",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_feature = X_train['Text'].apply(lambda x: extract_feature(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "022de04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_feature = X_test['Text'].apply(lambda x: extract_feature(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bc4e0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.20588235294117646\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.16      0.19       210\n",
      "           1       0.18      0.23      0.20       249\n",
      "           2       0.22      0.30      0.25       263\n",
      "           3       0.20      0.25      0.22       240\n",
      "           4       0.29      0.02      0.04        90\n",
      "           5       0.19      0.13      0.15       206\n",
      "\n",
      "    accuracy                           0.21      1258\n",
      "   macro avg       0.22      0.18      0.18      1258\n",
      "weighted avg       0.21      0.21      0.20      1258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train a Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_feature.to_list(), y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test_feature.to_list())\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258b5dcc",
   "metadata": {},
   "source": [
    "## Corpus Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c46f7de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
